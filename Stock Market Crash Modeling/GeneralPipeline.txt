The purpose of this data science based project is to gain a better understanding of the process of
building a data pipeline

Pipeline:

grab data, verify reliability, etc. ->
    inspect, analyze, clean, potentially morph into different shape, etc. ->
        descriptive statistics, graphing, etc. ->
            build models, verify them, tune, make sure you understand theoretical and application contexts ->
                test models on various datasets to help with previous step ->
                    let data flow through the models ->
                        analyze results, prepare findings for others

7 step process for data related problems

The area of focus here is modeling financial crashes




